#Экспериментировать с различными стратегиями разбиения документов на чанки
при разбиении chunk_size=500, chunk_overlap=50 получилось 377 чанков
бот смог ответить только на 1й вопрос
при разбиении chunk_size=1500, chunk_overlap=500 получилос 132 чанка 
бот так же смог ответить только на 1й вопрос и ответ изменился на менее релевантный
при разбиении chunk_size=800, chunk_overlap=100 получилос 246 чанков
бот не ответил ни на один вопрос
при разбиении пор структуре вышло 246 чанков
бот ответил на первые два вопроса

#подключение json
при подключении парсинга json вышло 458 чанков (PDF: 246, JSON: 212)
модель с Fireworks  не ответила ни на один вопрос при этом время от времени стала падать в ошибку too many requests
#Смена модели на локальную 
воспользовался olama 
подключил локально модель aroxima/multilingual-e5-large-instruct:latest
и наконец получил ответ на 3й вопрос а так же все ответы по JSON датасету
правда теперь не получил ответы на первые 2 вопроса
ответы приходят с большей задержкой но в пределах разумного